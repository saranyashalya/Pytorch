{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference: https://www.youtube.com/watch?v=CNuI8OWsppg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_lines.txt\")\n",
    "conv_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "# visualize some lines\n",
    "\n",
    "with open(lines_filepath, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting each values into different fields in dictionary\n",
    "line_field = ['lineID','characterID','movieID','character','text']\n",
    "lines ={}\n",
    "with open(lines_filepath,'r', encoding ='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        lineObj ={}\n",
    "        for i, field in enumerate(line_field):\n",
    "            lineObj[field]=values[i]\n",
    "        lines[lineObj['lineID']] = lineObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group fields of lines from loadlines into conversations based on movie_conversations.txt\n",
    "\n",
    "conv_fields = ['characeter1ID','character2ID','movieID','utteranceIDs']\n",
    "conversations = []\n",
    "with open(conv_filepath,'r', encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' +++$+++ ')\n",
    "        convObj = {}\n",
    "        for i, field in enumerate(conv_fields):\n",
    "            convObj[field]=values[i]\n",
    "        \n",
    "        #convert string into list \n",
    "        lineIds = eval(convObj['utteranceIDs'])\n",
    "        #Reassemble lines\n",
    "        convObj['lines']=[]\n",
    "        for lineId in lineIds:\n",
    "            convObj['lines'].append(lines[lineId])\n",
    "        conversations.append(convObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract qa pairs\n",
    "qa_pairs =[]\n",
    "for conversation in conversations:\n",
    "    for i in range(len(conversation['lines'])-1):\n",
    "        inputLine = conversation['lines'][i]['text'].strip()\n",
    "        targetLine = conversation['lines'][i+1]['text'].strip()\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine, targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " writing newly formatted file\n",
      "Done writing to file\n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "delimiter ='\\t'\n",
    "\n",
    "delimiter = str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "\n",
    "#write new csv file\n",
    "print(\"\\n writing newly formatted file\")\n",
    "with open(datafile,'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter = delimiter)\n",
    "    for pairs in qa_pairs:\n",
    "        writer.writerow(pairs)\n",
    "print(\"Done writing to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "# visualize some lines\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "with open(datafile ,'rb') as file:\n",
    "    lines= file.readlines()\n",
    "for line in lines[:8]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token =0\n",
    "SOS_token=1\n",
    "EOS_token=2\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index ={}\n",
    "        self.word2count ={}\n",
    "        self.index2word = {PAD_token : \"PAD\", SOS_token : \"SOS\", EOS_token : \"EOS\"}\n",
    "        self.num_words = 3\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words +=1\n",
    "        else:\n",
    "            self.word2count[word] +=1\n",
    "            \n",
    "    #remove words below a certain threshold\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v>= min_count:\n",
    "                keep_words.append(k)\n",
    "            \n",
    "        print('keep words {} / {} = {:.4f}'.format(len(keep_words), len(self.word2index), len(keep_words)/len(self.word2index)) )\n",
    "        \n",
    "        # reinitialize dictionaries\n",
    "        self.word2index ={}\n",
    "        self.word2count ={}\n",
    "        self.index2word = {PAD_token : \"PAD\", SOS_token : \"SOS\", EOS_token : \"EOS\"}\n",
    "        self.num_words = 3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn unicode to ascii\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase, trim white space, lines..etc and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\" , r\" \", s)\n",
    "    s = re.sub(r\"\\s+\",r\" \",s).strip()\n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa aaa !s s dd ?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(\"aaa13aaa!s's    dd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and procssing file..pls wait\n",
      "Done processing\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "print(\"Reading and procssing file..pls wait\")\n",
    "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\n",
    "pairs = [[normalizeString(s) for s in pairs.split('\\t')] for pairs in lines]\n",
    "print(\"Done processing\")\n",
    "voc = Vocabulary(\"cornell movie-dialogs corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442563"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns true if both the sentences have words < max length\n",
    "MAX_LENGTH = 10\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) <MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64271 pairs/conversations in the dataset\n",
      "After filtering 64271 pairs/conversations in the dataset\n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair)>1]\n",
    "print(\"There are {} pairs/conversations in the dataset\".format(len(pairs)))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"After filtering {} pairs/conversations in the dataset\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:  18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "# Loop through each pairs and add them as part of vocabulary\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print('Counted words: ', voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3 # minimum word count for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # check input sequence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        #check output sequence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "        \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "        \n",
    "    print('Trimmed from {} pairs to {}, {:.4f} of total'.format(len(pairs), len(keep_pairs), len(keep_pairs)/len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(voc, pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [58, 2]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some sample for testing\n",
    "inp = []\n",
    "out =[]\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "print(inp)\n",
    "print(len(inp))\n",
    "indexes = [indexesFromSentence(voc, sentence) for sentence in inp]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(l, fillvalue =0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue = fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leng = [len(ind) for ind in indexes]\n",
    "max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function\n",
    "test_result = zeroPadding(indexes)\n",
    "print(len(test_result))\n",
    "test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l, value =0):\n",
    "    m=[]\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_result = binaryMatrix(test_result)\n",
    "binary_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded input sequence tensor and as well as a tensor of lengths for each of the sequence in the batch\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key = lambda x : len(x[0].split(\" \")), reverse = True)\n",
    "    input_batch, output_batch = [],[]\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len =outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input variable:\n",
      "tensor([[ 242,  289,   23,   60,  536],\n",
      "        [ 188,   83,    4,   53,  709],\n",
      "        [  36,  219,    4,  598, 3381],\n",
      "        [ 199,   27,    4,  135,    2],\n",
      "        [   4,  158, 1308, 4189,    0],\n",
      "        [ 716,  480,    6,    4,    0],\n",
      "        [ 228,    4,    2,    2,    0],\n",
      "        [   4,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([9, 8, 7, 7, 4])\n",
      "target variable:\n",
      "tensor([[  25,  124,    4,  571,    7],\n",
      "        [  24,    9,    4,  367,   18],\n",
      "        [   4, 1014,    4,   59,   36],\n",
      "        [   2, 1215,    4,   83,    6],\n",
      "        [   0, 1014,    4,   96,    2],\n",
      "        [   0,    4,    4,    4,    0],\n",
      "        [   0,    4,    2,    2,    0],\n",
      "        [   0,    4,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 0],\n",
      "        [0, 1, 1, 1, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 9\n"
     ]
    }
   ],
   "source": [
    "# example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input variable:\")\n",
    "print(input_variable)\n",
    "print(\"lengths:\",lengths)\n",
    "print(\"target variable:\")\n",
    "print(target_variable)\n",
    "print(\"mask:\",mask )\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers = 1, dropout =0):\n",
    "        super(EncoderRNN).__init__()\n",
    "        self.n_layers =n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout(0 if n_layers ==1 else dropout), bidirectional = True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden = None):\n",
    "        #input_seq = shape(max_length, batch_size)\n",
    "        #input_lengths = list of sentence lengths \n",
    "        # hidden = shape(n_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        embedded = self.embedding(input_seq)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs,_ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:,:,:self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim = 2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers = 1, dropout =0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        #Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers==1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size*2 , hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context),1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        \n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_out, target, mask):\n",
    "    nTotal = mask.sum() # how many elements should we consider\n",
    "    target = target.view(-1,1)\n",
    "    \n",
    "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
    "    crossEntropy = -torch.log(gathered_tensor)\n",
    "    loss = crossEntropy.masked_select(mask)\n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input variable:\n",
      "tensor([[  76,    7,   25,   77,   53],\n",
      "        [ 271,  488,   89,   80, 5813],\n",
      "        [ 117,  158,  553,   47, 1750],\n",
      "        [ 935,  123,   76,   36,    4],\n",
      "        [ 115, 2498,    4,    6,    2],\n",
      "        [  76,    4,    2,    2,    0],\n",
      "        [7214,    2,    0,    0,    0],\n",
      "        [   6,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([9, 8, 7, 7, 4])\n",
      "target variable:\n",
      "tensor([[  34,  124,  553, 1596, 5813],\n",
      "        [   4, 1643,   50,    4,    4],\n",
      "        [   2,   25,    6,    2,    2],\n",
      "        [   0,  112,    2,    0,    0],\n",
      "        [   0,  197,    0,    0,    0],\n",
      "        [   0,  117,    0,    0,    0],\n",
      "        [   0,   24,    0,    0,    0],\n",
      "        [   0,   75,    0,    0,    0],\n",
      "        [   0,   45,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-45fc1795c7a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Define the encoder and decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_n_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLuongAttnDecoderRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_n_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-5b5edc81a096>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, hidden_size, embedding, n_layers, dropout)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     raise AttributeError(\n\u001b[1;32m--> 617\u001b[1;33m                         \"cannot assign module before Module.__init__() call\")\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[0mremove_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "#Visualing 1 iteration\n",
    "small_batch_size =5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, length, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input variable:\")\n",
    "print(input_variable)\n",
    "print(\"lengths:\",lengths)\n",
    "print(\"target variable:\")\n",
    "print(target_variable)\n",
    "print(\"mask:\",mask )\n",
    "print(\"max_target_len:\", max_target_len)\n",
    "\n",
    "# define parameters\n",
    "hidden_size = 500\n",
    "encoder_n_layers =2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "attn_model = 'dot'\n",
    "embedding = nn.Embedding(voc.num_words,hidden_size)\n",
    "\n",
    "# Define the encoder and decoder\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "#Initialize optimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "decoder_optimizer = optim.Adam(encoder.parameters(), lr =0.0001)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss =0\n",
    "print_losses =[]\n",
    "n_totals=0\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"Encoder output shape:\", encoder_outputs.shape)\n",
    "print(\"Last Encoder Hidden Shape: \", encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "print(\"Initial Decoder Input shape:\", decoder_input.shape)\n",
    "print(decoder_input)\n",
    "\n",
    "decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "print(\"Initial Decoder hidden state shape:\", decoder_hidden.shape)\n",
    "print(\"\\n\")\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(\"Now Let's look what is happening in every timestep of the GRU!\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Assume we are using teacher forcing\n",
    "\n",
    "for t in range(max_target_len):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    print(\"Decoder output shape:\", decoder_output.shape)\n",
    "    print(\"Decoder hidden shape:\", decoder_hidden.shape)\n",
    "    \n",
    "    decoder_input = target_variable[t].view(-1,1)\n",
    "    print(\"The target variable at the current timestamp before reshaping:\", target_variable[t])\n",
    "    print(\"The target variable at the current timestamp shape before reshaping:\", target_variable[t].shape)\n",
    "    print(\"The Decoder input shape(reshape the target variable):\", decoder_input.shape)\n",
    "    \n",
    "    print(\"The mask at the current timestamp:\", mask[t])\n",
    "    print(\"The mast at the current timestamp shape:\", mask[t].shape)\n",
    "    mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "    print(\"Mask loss:\", mask_loss)\n",
    "    print(\"Total:\",nTotal)\n",
    "    \n",
    "    loss +=mask_loss\n",
    "    print_losses.append(mask_loss.item() *nTotal)\n",
    "    print(print_losses)\n",
    "    \n",
    "    n_totals += nTotal\n",
    "    print(n_totals)\n",
    "    encoder.optimizer.step()\n",
    "    decoder.optimizer.step()\n",
    "    returned_loss= sum(print_losses)/n_totals\n",
    "    print(\"REturned loss:\", returned_loss)\n",
    "    print(\"\\n\")\n",
    "    print(\"---------------------------------Done one Timestep------------------------------\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training module\n",
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, \n",
    "         decoder_optimizer, batch_size, clip, max_length = MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable =target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "    \n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_variable[t].view(-1,1)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss +=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals += nTotal\n",
    "            \n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _,topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            \n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() *nTotal)\n",
    "            n_totals += nTotal\n",
    "            \n",
    "    loss.backward()\n",
    "    \n",
    "    _=torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _= torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses) / n_totals\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
